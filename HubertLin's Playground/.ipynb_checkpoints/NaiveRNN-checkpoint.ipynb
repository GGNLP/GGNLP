{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas\n",
    "\n",
    "1. 我們有已經 label 成 same question 的 data ，那我們也許可以另外 train 一個 model 可以根據 input 的句子 sequential 生成新的\"換句話說\"句子?\n",
    "2. curriculum learning\n",
    "3. Ensombling:\n",
    "\n",
    "        a. Naive RNN\n",
    "        b. xgboost\n",
    "        \n",
    "\n",
    "---\n",
    "\n",
    "1. Since we already have data that labelled as same question paris. Is it possible for us to train another model which can sequetially generate a same question string depends on the input? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_map = pickle.load(open('../dataset/processed/dec_map.pkl','rb'))\n",
    "enc_map = pickle.load(open('../dataset/processed/enc_map.pkl','rb'))\n",
    "embedding_matrix = pickle.load(open('../dataset/processed/embedding_matrix.pkl','rb'))\n",
    "\n",
    "df_train = pickle.load(open('../dataset/processed/processed_training_data.pkl','rb'))\n",
    "df_test = pickle.load(open('../dataset/processed/processed_testing_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[19354, 32666, 44207, 42906, 23164, 42906, 304...</td>\n",
       "      <td>[19354, 32666, 44207, 42906, 23164, 42906, 304...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[19354, 32666, 44207, 43024, 36339, 10433, 3, ...</td>\n",
       "      <td>[19354, 46871, 30660, 31592, 44207, 9371, 3022...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[8861, 23291, 8972, 31895, 44207, 42532, 36339...</td>\n",
       "      <td>[8861, 23291, 9512, 42532, 22036, 31896, 23164...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[19400, 20710, 8972, 34717, 45992, 3, 8861, 23...</td>\n",
       "      <td>[7257, 44207, 39954, 46574, 5, 32666, 27075, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[19372, 36439, 27001, 31811, 46391, 39195, 3, ...</td>\n",
       "      <td>[19372, 29136, 46871, 43570, 31811, 40880, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[3, 8972, 20710, 19889, 4393, 17404, 4381, 353...</td>\n",
       "      <td>[6, 19889, 44949, 4393, 7, 12388, 20852, 21315...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[16669, 8972, 23153, 3]</td>\n",
       "      <td>[19354, 33011, 4, 20158, 20852, 28784, 29664, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[8861, 23291, 8972, 22036, 19889, 30182, 3]</td>\n",
       "      <td>[19354, 41727, 8972, 27111, 44492, 22036, 1988...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[19367, 27111, 47026, 45728, 3, 32277, 36339, 4]</td>\n",
       "      <td>[19367, 27111, 47026, 45728, 5, 32277, 36339, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[12442, 3, 4350, 8972, 30538, 35578, 4637, 4, 5]</td>\n",
       "      <td>[8861, 27111, 8972, 30538, 12442, 6, 29400, 29...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          question1  \\\n",
       "0   0  [19354, 32666, 44207, 42906, 23164, 42906, 304...   \n",
       "1   1  [19354, 32666, 44207, 43024, 36339, 10433, 3, ...   \n",
       "2   2  [8861, 23291, 8972, 31895, 44207, 42532, 36339...   \n",
       "3   3  [19400, 20710, 8972, 34717, 45992, 3, 8861, 23...   \n",
       "4   4  [19372, 36439, 27001, 31811, 46391, 39195, 3, ...   \n",
       "5   5  [3, 8972, 20710, 19889, 4393, 17404, 4381, 353...   \n",
       "6   6                            [16669, 8972, 23153, 3]   \n",
       "7   7        [8861, 23291, 8972, 22036, 19889, 30182, 3]   \n",
       "8   8   [19367, 27111, 47026, 45728, 3, 32277, 36339, 4]   \n",
       "9   9   [12442, 3, 4350, 8972, 30538, 35578, 4637, 4, 5]   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  [19354, 32666, 44207, 42906, 23164, 42906, 304...             0  \n",
       "1  [19354, 46871, 30660, 31592, 44207, 9371, 3022...             0  \n",
       "2  [8861, 23291, 9512, 42532, 22036, 31896, 23164...             0  \n",
       "3  [7257, 44207, 39954, 46574, 5, 32666, 27075, 2...             0  \n",
       "4      [19372, 29136, 46871, 43570, 31811, 40880, 6]             0  \n",
       "5  [6, 19889, 44949, 4393, 7, 12388, 20852, 21315...             1  \n",
       "6  [19354, 33011, 4, 20158, 20852, 28784, 29664, ...             0  \n",
       "7  [19354, 41727, 8972, 27111, 44492, 22036, 1988...             1  \n",
       "8   [19367, 27111, 47026, 45728, 5, 32277, 36339, 6]             0  \n",
       "9  [8861, 27111, 8972, 30538, 12442, 6, 29400, 29...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_question(question, enc_map):\n",
    "    \n",
    "    if type(question)!=str or question==\"\":\n",
    "        return [enc_map['<ST>'], enc_map['<ED>']]\n",
    "    \n",
    "    def map_wrod(word):\n",
    "        return enc_map[word] if word in enc_map else enc_map['<RARE>']\n",
    "         \n",
    "    \n",
    "    # identify special characters that separate words : (space) ' ! \" ? @ ^ + * / . , ~ ( ) [ ] { } & | ` $ % = : ; < >  \n",
    "    separator = '(?=[\\s\\'!\"?@\\^+*/\\.,~\\(\\)\\[\\]\\{\\}\\&\\|`\\$\\%\\=:;\\<\\>]|$)'\n",
    "    single_word = '[\\S]+' # non-empty is enough here\n",
    "    \n",
    "    words_list = re.findall(single_word+separator, question)\n",
    "    \n",
    "    return [enc_map['<ST>']] + [map_wrod(word) for word in words_list] + [enc_map['<ED>']] \n",
    "    \n",
    "    \n",
    "def dec_question(question, dec_map):\n",
    "    return [dec_map[enc_value] for enc_value in question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIrH9fwEQOUVI8FKHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc94f266d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8e7f5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_counter = [0]*238 # longest question is 237 words long\n",
    "\n",
    "for i,data in df_train.iterrows():\n",
    "    q1 = eval(data['question1'])\n",
    "    q2 = eval(data['question2'])\n",
    "    \n",
    "    len_counter[len(q1)-2] += 1\n",
    "    len_counter[len(q2)-2] += 1\n",
    "        \n",
    "\n",
    "plt.plot(len_counter)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(len_counter[0:40])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so, use 30 words as length of model input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_to_list_and_clip(data, clip_st_ed=False):\n",
    "    \n",
    "    clip_len = 30\n",
    "    \n",
    "    if clip_st_ed:\n",
    "        data['question1'] = eval(data['question1'])[1:-1]\n",
    "        data['question2'] = eval(data['question2'])[1:-1]\n",
    "    \n",
    "    if len(data['question1'])<clip_len:\n",
    "        data['question1'] = data['question1'] + [enc_map['<ED>']] * (30-len(data['question1']))\n",
    "    else:\n",
    "        data['question1'] = data['question1'][:30]\n",
    "        \n",
    "    if len(data['question2'])<clip_len:\n",
    "        data['question2'] = data['question2'] + [enc_map['<ED>']] * (30-len(data['question2']))\n",
    "    else:\n",
    "        data['question2'] = data['question2'][:30]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = df_train.apply(change_to_list_and_clip, axis=1)\n",
    "pickle.dump(df_transformed, open('../dataset/processed/df_train_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = pickle.load(open('../dataset/processed/df_train_hubertLin_version.pkl', 'rb'))\n",
    "\n",
    "diff_questions = df_transformed.where(df_transformed['is_duplicate']==0).dropna().reset_index(drop=True)\n",
    "same_questions = df_transformed.where(df_transformed['is_duplicate']==1).dropna().reset_index(drop=True)\n",
    "\n",
    "pickle.dump(diff_questions, open('../dataset/processed/df_train_diff_hubertLin_version.pkl', 'wb'))\n",
    "pickle.dump(same_questions, open('../dataset/processed/df_train_same_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = df_test.apply(change_to_list_and_clip, axis=1)\n",
    "pickle.dump(df_transformed, open('../dataset/processed/df_test_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_map = pickle.load(open('../dataset/processed/dec_map.pkl','rb'))\n",
    "enc_map = pickle.load(open('../dataset/processed/enc_map.pkl','rb'))\n",
    "embedding_matrix = pickle.load(open('../dataset/processed/embedding_matrix.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def holdout(df, ratio=0.025): # we have 400,000 training data, 10000 for validation is enough\n",
    "    def gen_suffle_idx(arr):\n",
    "        random.shuffle(arr)\n",
    "        return arr\n",
    "    \n",
    "    holdout_size = int(len(df)*ratio)\n",
    "    idxes = gen_suffle_idx(np.arange(len(df)))\n",
    "    holdout_idxes = idxes[:holdout_size]\n",
    "    train_idxes = idxes[holdout_size:]\n",
    "    \n",
    "    df_train = df.iloc[train_idxes].dropna().reset_index(drop=True)\n",
    "    df_val   = df.iloc[holdout_idxes].dropna().reset_index(drop=True)\n",
    "    \n",
    "    return df_train, df_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, GRU, Reshape, Dense, merge, Dropout, BatchNormalization, LSTM, MaxoutDense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.layers.noise import GaussianNoise\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def naive_model():\n",
    "\n",
    "    # hyper-parameters that should be passed as function argument\n",
    "    \n",
    "    EMBEDDING_SIZE = 300\n",
    "    vocab_size = len(enc_map)\n",
    "    vocab_dim = EMBEDDING_SIZE # in my case is 300\n",
    "    text_length = 30 # how many words are we going to feed in one time\n",
    "    clipnorm = 1\n",
    "    \n",
    "    lstm_output = 64\n",
    "\n",
    "#     gru = GRU(256, dropout=0.2)\n",
    "    gru = LSTM(lstm_output, dropout=0.3, recurrent_dropout=0.3)\n",
    "    \n",
    "    # embed our encoded question to embedded vector\n",
    "\n",
    "    encoded_question_input1 = Input(shape=(text_length,))\n",
    "\n",
    "    x = Embedding(output_dim = vocab_dim, \n",
    "                  input_dim = vocab_size, \n",
    "                  init = 'glorot_uniform',       # to be honest, I don't know what is this\n",
    "                  input_length = text_length, \n",
    "                  weights = [embedding_matrix]   # our embedding_matrix\n",
    "                 )(encoded_question_input1)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    text_embedded1 = Reshape((1,vocab_dim*text_length))(x)\n",
    "    gru1 = gru(text_embedded1)\n",
    "\n",
    "    \n",
    "    # embed our encoded question to embedded vector\n",
    "\n",
    "    encoded_question_input2 = Input(shape=(text_length,))\n",
    "\n",
    "    x = Embedding(output_dim = vocab_dim, \n",
    "                  input_dim = vocab_size, \n",
    "                  init = 'glorot_uniform',       # to be honest, I don't know what is this\n",
    "                  input_length = text_length, \n",
    "                  weights = [embedding_matrix]   # our embedding_matrix\n",
    "                 )(encoded_question_input2)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    text_embedded2 = Reshape((1,vocab_dim*text_length))(x)\n",
    "    gru2 = gru(text_embedded2)\n",
    "    \n",
    "\n",
    "    # feed to RNN model\n",
    "    x = merge([gru1, gru2], mode='concat', concat_axis=-1)\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "#     x = Dense(60, activation='relu')(x)\n",
    "    x = MaxoutDense(lstm_output//2)(x) # ex: MaxoutDense(output_dim=1,nb_feature=3,input_dim=1)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # compile the model\n",
    "    \n",
    "    model = Model(input=[encoded_question_input1, encoded_question_input2], output=out)\n",
    "    # choose objective and optimizer\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-3))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(embeddings_initializer=\"glorot_uniform\", output_dim=300, input_length=30, input_dim=47245, weights=[array([[-...)`\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(embeddings_initializer=\"glorot_uniform\", output_dim=300, input_length=30, input_dim=47245, weights=[array([[-...)`\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:529: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model = naive_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on all data directly. Overcome the imbalance problem by directly assign weights for each class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_pos_label_ratio = 0.1746\n",
    "\n",
    "weights = {\n",
    "    0: 1.309028344,\n",
    "    1: 0.472001959\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pickle.load(open('../dataset/processed/df_train_hubertLin_version.pkl', 'rb'))\n",
    "\n",
    "df_transformed, df_validation = holdout(df_transformed, ratio=0.025)\n",
    "\n",
    "X_train = [np.vstack(df_transformed['question1']), np.vstack(df_transformed['question2'])]\n",
    "y_train = np.vstack(df_transformed['is_duplicate'])\n",
    "\n",
    "X_val = [np.vstack(df_validation['question1']), np.vstack(df_validation['question2'])]\n",
    "y_val = np.vstack(df_validation['is_duplicate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_pos_label_ratio = 0.1746\n",
    "\n",
    "pos_labels = df_transformed['is_duplicate']==1\n",
    "pos_label_ratio = sum(pos_labels)/len(pos_labels)\n",
    "weights = {\n",
    "    0: (1-test_set_pos_label_ratio) / (1-pos_label_ratio),\n",
    "    1: test_set_pos_label_ratio/pos_label_ratio\n",
    "}\n",
    "\n",
    "validation_weights = np.repeat(weights[1], len(y_val))\n",
    "validation_weights[y_val.reshape(len(y_val))==0] = weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 394183 samples, validate on 10107 samples\n",
      "Epoch 1/1000\n",
      "394183/394183 [==============================] - 359s - loss: 0.4102 - val_loss: 0.3579\n",
      "Epoch 2/1000\n",
      " 82176/394183 [=====>........................] - ETA: 275s - loss: 0.3347"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "]\n",
    "    \n",
    "try:\n",
    "    model.fit(X_train, \n",
    "              y_train,\n",
    "              class_weight=weights,\n",
    "              epochs=1000, \n",
    "              batch_size=768,\n",
    "              shuffle=True,\n",
    "              validation_data=(X_val,y_val,validation_weights), \n",
    "              callbacks=callbacks,\n",
    "              verbose=1)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nEarly stop by user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "pred[pred==1] = 0.999999\n",
    "pred[pred==0] = 0.000001\n",
    "\n",
    "print('log_loss=',log_loss(y_val, pred))\n",
    "print('roc_auc=',roc_auc_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commonly overfit around loss ~ 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on batch , uses unsampling/downsampling to gaurantee the pos/neg labels are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_questions = pickle.load(open('../dataset/processed/df_train_diff_hubertLin_version.pkl', 'rb'))\n",
    "same_questions = pickle.load(open('../dataset/processed/df_train_same_hubertLin_version.pkl', 'rb'))\n",
    "\n",
    "diff_questions, diff_val = holdout(diff_questions)\n",
    "same_questions, same_val = holdout(same_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404290 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      " 73728/404290 [====>.........................] - ETA: 309s - loss: 0.5912\n",
      "Early stop by user\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "\n",
    "def gen_suffle_idx(arr):\n",
    "    random.shuffle(arr)\n",
    "    return arr\n",
    "\n",
    "def data_gen():\n",
    "    a = np.arange(batch_size)\n",
    "    while True:\n",
    "        \n",
    "        rand = [random.randint(0,len(same_questions)-1) for i in range(batch_size//2)]\n",
    "        pos_selected = same_questions.ix[rand]\n",
    "        rand = [random.randint(0,len(diff_questions)-1) for i in range(batch_size//2)]\n",
    "        neg_selected = diff_questions.ix[rand]\n",
    "        \n",
    "        selected  = pos_selected.append(neg_selected).reset_index(drop=True)\n",
    "        selected = selected.ix[gen_suffle_idx(a)]\n",
    "\n",
    "#         batch_size = len(sanity_check)\n",
    "#         a = np.arange(batch_size)\n",
    "#         selected = sanity_check.ix[gen_suffle_idx(a)]\n",
    "        \n",
    "        q1 = np.array([data['question1'] for i,data in selected.iterrows()])\n",
    "        q2 = np.array([data['question2'] for i,data in selected.iterrows()])\n",
    "        \n",
    "        # randomly swap two training question pair\n",
    "        swap_idxes = [random.randint(0,len(selected)-1) for i in range(batch_size//2)]\n",
    "        for i in swap_idxes:\n",
    "            q1[i] , q2[i] = q2[i] , q1[i]\n",
    "        \n",
    "        y = np.array([data['is_duplicate'] for i,data in selected.iterrows()])\n",
    "\n",
    "        yield [q1, q2], y\n",
    "\n",
    "def gen_validation(size):\n",
    "    \n",
    "    a = np.arange(size)\n",
    "    \n",
    "    rand = [random.randint(0,len(same_val)-1) for i in range(size//2)]\n",
    "    pos_selected = same_val.ix[rand]\n",
    "    rand = [random.randint(0,len(diff_val)-1) for i in range(size//2)]\n",
    "    neg_selected = diff_val.ix[rand]\n",
    "    \n",
    "    selected  = pos_selected.append(neg_selected).reset_index(drop=True)\n",
    "    selected = selected.ix[gen_suffle_idx(a)]\n",
    "\n",
    "    q1 = np.array([data['question1'] for i,data in selected.iterrows()])\n",
    "    q2 = np.array([data['question2'] for i,data in selected.iterrows()])\n",
    "\n",
    "    y = np.array([data['is_duplicate'] for i,data in selected.iterrows()])\n",
    "\n",
    "    return [q1, q2], y, class_weights\n",
    "    \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "]\n",
    "    \n",
    "try:\n",
    "    validation_data = gen_validation(10000)\n",
    "    model.fit_generator(data_gen(), 50, epochs=1000, validation_data=validation_data, callbacks=callbacks)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nEarly stop by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss 約 converge 在 0.49~0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    q = diff_questions.ix[i]\n",
    "    x1 = np.array([q['question1']])\n",
    "    x2 = np.array([q['question2']])\n",
    "    print(model.predict([x1,x2])[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def predict(i,q):\n",
    "    \n",
    "#     x1 = np.array([list(q['question1'])])\n",
    "#     x2 = np.array([list(q['question2'])])\n",
    "#     return model.predict([x1,x2])[:,1]\n",
    "\n",
    "# df_test.head()\n",
    "# for i in range(10):\n",
    "#     df = same_questions\n",
    "#     print(dec_question(df.ix[i]['question1'], dec_map))\n",
    "#     print(dec_question(df.ix[i]['question2'], dec_map))\n",
    "#     print(predict(i,df.ix[i]))\n",
    "#     print(df.ix[i]['is_duplicate'])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../model/HubertLin_naive_LSTM120.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customized testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_question_pair(question_pair_list, enc_map, capsulate_st_ed=False):\n",
    "\n",
    "    def enc_question(question):\n",
    "\n",
    "        if type(question)!=str or question==\"\":\n",
    "            if capsulate_st_ed:\n",
    "                return [enc_map['<ST>'], enc_map['<ED>']]\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        def map_wrod(word):\n",
    "            if word in enc_map:\n",
    "                return enc_map[word]\n",
    "            elif word in rare_words:\n",
    "                idx = np.where(np.array(rare_words)==word)[0][0]\n",
    "                return enc_map['<RARE' + str(idx) + '>']\n",
    "            else:\n",
    "                rare_words.append(word)\n",
    "                return enc_map['<RARE' + str(len(rare_words)-1) + '>']\n",
    "\n",
    "        # identify special characters that separate words : (space) ' ! \" ? @ ^ + * / . , ~ ( ) [ ] { } & | ` $ % = : ; < >  \n",
    "        separator = '(?=[\\s\\'!\"?@\\^+*/\\.,~\\(\\)\\[\\]\\{\\}\\&\\|`\\$\\%\\=:;\\<\\>\\-]|$)'\n",
    "        single_word = '[^\\s\\-]+' # non-empty is enough here\n",
    "\n",
    "        words_list = re.findall(single_word+separator, question)\n",
    "\n",
    "        if capsulate_st_ed:\n",
    "            return [enc_map['<ST>']] + [map_wrod(word) for word in words_list] + [enc_map['<ED>']] \n",
    "        else:\n",
    "            return [map_wrod(word) for word in words_list]\n",
    "        \n",
    "    # This array is a local cache that identify those non-encoded rare words. \n",
    "    # We'll assign identical index (in this question pair) for each of rare words\n",
    "    rare_words = []\n",
    "    \n",
    "    return enc_question(question_pair_list[0]) , enc_question(question_pair_list[1])\n",
    "    \n",
    "    \n",
    "def dec_question(question, dec_map):\n",
    "    return [dec_map[enc_value] for enc_value in question]\n",
    "\n",
    "def clip_length(data, clip_st_ed=False):\n",
    "    \n",
    "    clip_len = 30\n",
    "    \n",
    "    if clip_st_ed:\n",
    "        data[0] = eval(data[0])[1:-1]\n",
    "        data[1] = eval(data[1])[1:-1]\n",
    "    \n",
    "    if len(data[0])<clip_len:\n",
    "        data[0] = data[0] + [enc_map['<ED>']] * (30-len(data[0]))\n",
    "    else:\n",
    "        data[0] = data[0][:30]\n",
    "        \n",
    "    if len(data[1])<clip_len:\n",
    "        data[1] = data[1] + [enc_map['<ED>']] * (30-len(data[1]))\n",
    "    else:\n",
    "        data[1] = data[1][:30]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Which', 'is', 'the', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>']\n",
      "['Where', 'was', 'training', '<RARE0>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>']\n",
      "\n",
      "Predicting is same question proba = [[ 0.15064879]]\n"
     ]
    }
   ],
   "source": [
    "a = df_test.ix[100]\n",
    "q1 = dec_question(a['question1'], dec_map)\n",
    "q2 = dec_question(a['question2'], dec_map)\n",
    "print(q1)\n",
    "print(q2)\n",
    "\n",
    "pred = model.predict([np.array([a['question1']]), np.array([a['question2']])])\n",
    "print('\\nPredicting is same question proba =', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'your', 'favorite', 'food', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>']\n",
      "['Which', 'is', 'your', 'favorite', 'one', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>', '<ED>']\n",
      "Predicting is same question proba = [[ 0.58142167]]\n"
     ]
    }
   ],
   "source": [
    "q1 = 'I am a good man'\n",
    "q2 = 'A good man is me'\n",
    "\n",
    "q1 = 'What is your favorite food'\n",
    "q2 = 'Which is your favorite one'\n",
    "\n",
    "sp1 = q1.split(' ')\n",
    "sp2 = q2.split(' ')\n",
    "\n",
    "enc1, enc2 = enc_question_pair([q1,q2], enc_map)\n",
    "enc1, enc2 = clip_length([enc1,enc2])\n",
    "print(dec_question(enc1,dec_map))\n",
    "print(dec_question(enc2,dec_map))\n",
    "\n",
    "pred = model.predict([np.array([enc1]), np.array([enc2])])\n",
    "print('Predicting is same question proba =', pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# try:\n",
    "#     model==None\n",
    "# except:\n",
    "#     model = load_model('./model/HubertLin_naive_2_GRU256_same.model')\n",
    "\n",
    "df_test = pickle.load(open('../dataset/processed/df_test_hubertLin_version.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "partition_size = 1000\n",
    "\n",
    "def predict(i,q):\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(i*partition_size, '/', len(df_test))\n",
    "    \n",
    "    x1 = np.array(list(q['question1']))\n",
    "    x2 = np.array(list(q['question2']))\n",
    "    return model.predict([x1,x2])\n",
    "\n",
    "partition_len = len(df_test)//partition_size +1\n",
    "result = [predict(i,df_test.iloc[i*partition_size:(i+1)*partition_size]) for i in range(partition_len)]\n",
    "con = np.concatenate(result)\n",
    "df_result = pd.DataFrame({'test_id':np.arange(len(con)),'is_duplicate':con.reshape(len(con))}, columns=['test_id','is_duplicate'])\n",
    "df_result.to_csv('../result/prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction success\n"
     ]
    }
   ],
   "source": [
    "if len(df_result)!=2345796:\n",
    "    print('Your result prediction count is not fit to the testing data length 2345796 , yours:', len(df_result))\n",
    "else:\n",
    "    print('Prediction success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
