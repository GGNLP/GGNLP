{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genrate one of the magic features\n",
    "\n",
    "#### WHAT???\n",
    "\n",
    "We have done some word correction approach in data pre-processing phase. And it suddenly comes to me that the administator of this competition once said that \"there exists some machine generated questions in the data set\". And I guess some of those machine generated questions and simply adding typos. So the count of typos may shows some evidence of data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Nadam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "BASE_DIR = '../input/'\n",
    "EMBEDDING_FILE = '../../dataset/glove/glove.6B.300d.txt'\n",
    "TRAIN_DATA_FILE = '../../dataset/quora-question-pairs/train.csv'\n",
    "TEST_DATA_FILE = '../../dataset/quora-question-pairs/test.csv'\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## index word vectors\n",
    "########################################\n",
    "print('Indexing word vectors')\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(EMBEDDING_FILE, encoding='utf-8')\n",
    "count = 0\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %d word vectors of glove.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SpaCy `en_core_web_md` corpus...\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## Spell Checker with Glove\n",
    "########################################\n",
    "\n",
    "# Import spacy corpus, glove embeddings.\n",
    "import spacy\n",
    "import textacy\n",
    "\n",
    "print('Loading SpaCy `en_core_web_md` corpus...')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def word_prob(word):\n",
    "    \"Probability of word.\"\n",
    "    return nlp.vocab[word].prob\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    if nlp.vocab[word].prob > -15.0: \n",
    "        return word, False\n",
    "    else:\n",
    "        return max(candidates(word), key=word_prob), True\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return set([word] + known([word]) + known(edits1(word)) + known(edits2(word)))\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the vocabulary.\"\n",
    "    return [w for w in words if w in nlp.vocab]\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "abbr_dict = {\n",
    "    \"\\'s\":\" is\",\n",
    "    \"\\'re\":\" are\",\n",
    "\n",
    "    \"i'm\":\"i am\",\n",
    "    \"it's\":\"it is\",\n",
    "    \"\\'ve\":\" have\",\n",
    "\n",
    "    \"\\'ll\":\" will\",\n",
    "\n",
    "    \"won't\":\"will not\",\n",
    "    \"can't\":\"can not\",\n",
    "    \"\\'t\":\" not\",\n",
    "    \n",
    "}\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False, correct_words=True):\n",
    "    \n",
    "    if type(text)!=str:\n",
    "        text = ''\n",
    "    \n",
    "    # Remove spaces.\n",
    "    text = textacy.preprocess_text(text, lowercase=True)\n",
    "\n",
    "    # Handle Abbreviation.\n",
    "    for k, v in abbr_dict.items():\n",
    "        text = re.sub(r\"{}\".format(k), v, text)\n",
    "\n",
    "    if correct_words:\n",
    "        # Spelling correction\n",
    "        corrected_words = []\n",
    "        modified_count = 0\n",
    "        for doc in nlp(text):\n",
    "            # Don't correct special words\n",
    "            if doc.ent_type_ is not '' or doc.pos_ in ['PROPN', 'PUNCT']:\n",
    "                corrected_words.append(doc.text)\n",
    "            else:\n",
    "                corrected, is_modified = correction(doc.text)\n",
    "                corrected_words.append(corrected)\n",
    "                if is_modified:\n",
    "                    modified_count += 1\n",
    "\n",
    "        # Re-merge corrected words\n",
    "        text = \" \".join(corrected_words)\n",
    "        \n",
    "\n",
    "    # Text normalization\n",
    "    text = re.sub('[\\!\\?\\@\\^\\+\\*\\/\\,\\~\\|\\`\\=\\:\\;\\.\\#\\\\\\\\(\\)\\[\\]\\{\\}\\<\\>\\'\\\"]', ' ', text)\n",
    "\n",
    "    # Convert to lower case, remove punctuations and further text normalization.\n",
    "    text = textacy.preprocess_text(text, lowercase=True, no_punct=True, no_numbers=True, no_currency_symbols=True)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load raw data\n",
    "df_train = pd.read_csv('../dataset/quora-question-pairs/train.csv')\n",
    "df_test = pd.read_csv('../dataset/quora-question-pairs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# laod corrected lists\n",
    "[texts_1, texts_2, labels] = pickle.load(open('./lystdo_kernel/train_text_processed.pkl','rb'))\n",
    "[test_texts_1, test_texts_2, test_ids] = pickle.load(open('./lystdo_kernel/test_text_processed.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 how how\n",
      "1 do do\n",
      "2 i i\n",
      "3 enter enter\n",
      "4 a a\n",
      "5 new new\n",
      "6 email email\n",
      "7 i id\n",
      "8 d which\n",
      "9 i i\n",
      "10 can can\n",
      "11 access access\n",
      "12 to to\n",
      "13 recover recover\n",
      "14 my my\n",
      "15 facebook facebook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_diff(t1, t2, debug=False):\n",
    "    t1 = t1.split(' ')\n",
    "    t2 = t2.split(' ')\n",
    "    \n",
    "    count = 0\n",
    "    min_len = min(len(t1),len(t2))\n",
    "    \n",
    "    if len(t1)!=len(t2):\n",
    "\n",
    "        idx_1 = 0\n",
    "        idx_2 = 0\n",
    "\n",
    "        for i in range(min_len):\n",
    "            \n",
    "            # reaches end\n",
    "            if idx_1>=min_len or idx_2>=min_len:\n",
    "                break\n",
    "                \n",
    "            if debug:\n",
    "                print(i,  t1[idx_1], t2[idx_2])\n",
    "\n",
    "            if t1[idx_1]!=t2[idx_2]:\n",
    "\n",
    "                is_match = False\n",
    "\n",
    "                # try to find two words afterward on q1\n",
    "                try:\n",
    "                    for extra in range(1,2):\n",
    "                        if t1[idx_1+extra]==t2[idx_2]:\n",
    "                            idx_1 += extra+1\n",
    "                            idx_2 += 1\n",
    "                            count += extra\n",
    "                            is_match = True\n",
    "                            break\n",
    "                    if is_match:\n",
    "                        continue\n",
    "                except:\n",
    "                    pass # out of index\n",
    "\n",
    "                # try to find two words afterward on q2\n",
    "                try:\n",
    "                    for extra in range(1,2):\n",
    "                        if t1[idx_1]==t2[idx_2+extra]:\n",
    "                            idx_1 += 1\n",
    "                            idx_2 += extra+1\n",
    "                            count += extra\n",
    "                            is_match = True\n",
    "                            break\n",
    "                    if is_match:\n",
    "                        continue\n",
    "                except:\n",
    "                    pass # out of index\n",
    "\n",
    "                count += 1\n",
    "            idx_1 += 1\n",
    "            idx_2 += 1\n",
    "\n",
    "    else:\n",
    "        for i in range(min_len):\n",
    "            if t1[i]!=t2[i]:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# a = 'how would you find the zero of the function for math y frac 4x number number xnumber math'\n",
    "# b = 'how would you find the zero of the function for math y frac 4x number 36x x number math'\n",
    "\n",
    "a = 'how do i enter a new email i d which i can access to recover my facebook i d'\n",
    "b = 'how do i enter a new email id which i can access to recover my facebook id'\n",
    "\n",
    "get_diff(a,b, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 404290\n",
      "100000 / 404290\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9e0b87f4e2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtotal_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mwithout_correction_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_wordlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    243\u001b[0m                                        raise_cast_failure=True)\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   4068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4069\u001b[0m             block = make_block(block, placement=slice(0, len(axis)), ndim=1,\n\u001b[0;32m-> 4070\u001b[0;31m                                fastpath=True)\n\u001b[0m\u001b[1;32m   4071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4072\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComplexBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2677\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/types/common.py\u001b[0m in \u001b[0;36mis_categorical\u001b[0;34m(array)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m\"\"\" return if we are a categorical possibility \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nlplab/anaconda3/lib/python3.6/site-packages/pandas/types/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_typ'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# process training set\n",
    "\n",
    "SET = 'train'\n",
    "# SET = 'test'\n",
    "\n",
    "if SET == 'train':\n",
    "    df = df_train\n",
    "    corrected_1 = texts_1\n",
    "    corrected_2 = texts_2\n",
    "else:\n",
    "    df = df_test\n",
    "    corrected_1 = test_texts_1\n",
    "    corrected_2 = test_texts_2\n",
    "\n",
    "result_q1 = []\n",
    "result_q2 = []\n",
    "\n",
    "\n",
    "total_len = len(df)\n",
    "for i,series in df.iterrows():\n",
    "    \n",
    "    without_correction_1 = text_to_wordlist(series['question1'], correct_words=False)\n",
    "    without_correction_2 = text_to_wordlist(series['question2'], correct_words=False)\n",
    "    \n",
    "    try:\n",
    "        diff_1 = get_diff(corrected_1[i],without_correction_1)\n",
    "        diff_2 = get_diff(corrected_2[i],without_correction_2)\n",
    "    except:\n",
    "        print('Exception at idx', i)\n",
    "        print(corrected_1[i] + '\\n' + without_correction_1)\n",
    "        print()\n",
    "        print(corrected_2[i] + '\\n' + without_correction_2)\n",
    "        break\n",
    "    \n",
    "    result_q1.append(diff_1)\n",
    "    result_q2.append(diff_2)\n",
    "    \n",
    "    if i%100000==0:\n",
    "        print(i, '/', total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correction_count1</th>\n",
       "      <th>correction_count2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181402</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181406</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181407</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181408</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181409</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181410</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181413</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181417</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181418</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181420</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181421</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181422</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181423</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181425</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181428</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181431</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        correction_count1  correction_count2\n",
       "0                       0                  0\n",
       "1                       0                  0\n",
       "2                       1                  0\n",
       "3                       1                  0\n",
       "4                       1                  1\n",
       "5                       2                  0\n",
       "6                       0                  0\n",
       "7                       0                  2\n",
       "8                       0                  0\n",
       "9                       1                  1\n",
       "10                      0                  0\n",
       "11                      1                  1\n",
       "12                      0                  0\n",
       "13                      0                  0\n",
       "14                      0                  0\n",
       "15                      0                  0\n",
       "16                      0                  0\n",
       "17                      0                  0\n",
       "18                      2                  0\n",
       "19                      1                  2\n",
       "20                      1                  0\n",
       "21                      0                  0\n",
       "22                      1                  0\n",
       "23                      2                  0\n",
       "24                      0                  0\n",
       "25                      1                  0\n",
       "26                      0                  1\n",
       "27                      1                  1\n",
       "28                      1                  0\n",
       "29                      0                  0\n",
       "...                   ...                ...\n",
       "181402                  0                  0\n",
       "181403                  0                  0\n",
       "181404                  0                  0\n",
       "181405                  0                  0\n",
       "181406                  2                  0\n",
       "181407                  0                  1\n",
       "181408                  0                  0\n",
       "181409                  0                  0\n",
       "181410                  1                  0\n",
       "181411                  0                  0\n",
       "181412                  0                  0\n",
       "181413                  3                  0\n",
       "181414                  0                  0\n",
       "181415                  0                  0\n",
       "181416                  0                  0\n",
       "181417                  2                  0\n",
       "181418                  1                  0\n",
       "181419                  1                  1\n",
       "181420                  0                  3\n",
       "181421                  0                  1\n",
       "181422                  0                  1\n",
       "181423                  1                  5\n",
       "181424                  0                  0\n",
       "181425                  0                  1\n",
       "181426                  0                  0\n",
       "181427                  0                  0\n",
       "181428                  0                  2\n",
       "181429                  0                  1\n",
       "181430                  0                  0\n",
       "181431                  0                  1\n",
       "\n",
       "[181432 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(np.array([result_q1,result_q2]).reshape(-1,2), columns=['correction_count1', 'correction_count2'])\n",
    "# df_result.to_csv('./features_from_model/'+SET+'/correction_count.csv')\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " text_to_wordlist(text, remove_stopwords=False, stem_words=False, correct_words=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
