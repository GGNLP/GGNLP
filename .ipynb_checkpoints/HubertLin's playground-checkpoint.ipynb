{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas\n",
    "\n",
    "1. 我們有已經 label 成 same question 的 data ，那我們也許可以另外 train 一個 model 可以根據 input 的句子 sequential 生成新的\"換句話說\"句子?\n",
    "2. curriculum learning\n",
    "\n",
    "---\n",
    "\n",
    "1. Since we already have data that labelled as same question paris. Is it possible for us to train another model which can sequetially generate a same question string depends on the input? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_map = pickle.load(open('./dataset/processed/dec_map.pkl','rb'))\n",
    "enc_map = pickle.load(open('./dataset/processed/enc_map.pkl','rb'))\n",
    "embedding_matrix = pickle.load(open('./dataset/processed/embedding_matrix.pkl','rb'))\n",
    "df_train = pd.read_csv('./dataset/processed/processed_training_data.csv')\n",
    "df_test = pd.read_csv('./dataset/processed/processed_testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 13180, 23871, 33133, 32109, 16159, 32109, ...</td>\n",
       "      <td>[0, 13180, 23871, 33133, 32109, 16159, 32109, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 13180, 23871, 33133, 32193, 26775, 6810, 2...</td>\n",
       "      <td>[0, 13180, 35247, 22258, 23000, 33133, 6029, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 5656, 16261, 5732, 23249, 33133, 31803, 26...</td>\n",
       "      <td>[0, 5656, 16261, 6135, 31803, 15263, 23250, 16...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 13215, 14224, 5732, 25431, 34544, 2, 5656,...</td>\n",
       "      <td>[0, 4530, 33133, 29704, 35008, 2, 23871, 19319...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 13195, 26864, 19260, 23168, 34861, 2, 2, 2...</td>\n",
       "      <td>[0, 13195, 21038, 35247, 32641, 23168, 30444, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 2, 5732, 14224, 13561, 2508, 11764, 2500, ...</td>\n",
       "      <td>[0, 2, 13561, 33757, 2508, 2, 8190, 14333, 147...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[0, 11245, 5732, 16150, 2, 1]</td>\n",
       "      <td>[0, 13180, 24127, 2, 13770, 14333, 20743, 2146...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[0, 5656, 16261, 5732, 15263, 13561, 21870, 2, 1]</td>\n",
       "      <td>[0, 13180, 31154, 5732, 19349, 33375, 15263, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[0, 13190, 19349, 35374, 34337, 2, 23554, 2677...</td>\n",
       "      <td>[0, 13190, 19349, 35374, 34337, 2, 23554, 2677...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[0, 8226, 2, 2477, 5732, 22162, 26103, 2677, 2...</td>\n",
       "      <td>[0, 5656, 19349, 5732, 22162, 8226, 2, 21252, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          question1  \\\n",
       "0   0  [0, 13180, 23871, 33133, 32109, 16159, 32109, ...   \n",
       "1   1  [0, 13180, 23871, 33133, 32193, 26775, 6810, 2...   \n",
       "2   2  [0, 5656, 16261, 5732, 23249, 33133, 31803, 26...   \n",
       "3   3  [0, 13215, 14224, 5732, 25431, 34544, 2, 5656,...   \n",
       "4   4  [0, 13195, 26864, 19260, 23168, 34861, 2, 2, 2...   \n",
       "5   5  [0, 2, 5732, 14224, 13561, 2508, 11764, 2500, ...   \n",
       "6   6                      [0, 11245, 5732, 16150, 2, 1]   \n",
       "7   7  [0, 5656, 16261, 5732, 15263, 13561, 21870, 2, 1]   \n",
       "8   8  [0, 13190, 19349, 35374, 34337, 2, 23554, 2677...   \n",
       "9   9  [0, 8226, 2, 2477, 5732, 22162, 26103, 2677, 2...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  [0, 13180, 23871, 33133, 32109, 16159, 32109, ...             0  \n",
       "1  [0, 13180, 35247, 22258, 23000, 33133, 6029, 2...             0  \n",
       "2  [0, 5656, 16261, 6135, 31803, 15263, 23250, 16...             0  \n",
       "3  [0, 4530, 33133, 29704, 35008, 2, 23871, 19319...             0  \n",
       "4  [0, 13195, 21038, 35247, 32641, 23168, 30444, ...             0  \n",
       "5  [0, 2, 13561, 33757, 2508, 2, 8190, 14333, 147...             1  \n",
       "6  [0, 13180, 24127, 2, 13770, 14333, 20743, 2146...             0  \n",
       "7  [0, 13180, 31154, 5732, 19349, 33375, 15263, 1...             1  \n",
       "8  [0, 13190, 19349, 35374, 34337, 2, 23554, 2677...             0  \n",
       "9  [0, 5656, 19349, 5732, 22162, 8226, 2, 21252, ...             0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_question(question, enc_map):\n",
    "    \n",
    "    if type(question)!=str or question==\"\":\n",
    "        return [enc_map['<ST>'], enc_map['<ED>']]\n",
    "    \n",
    "    def map_wrod(word):\n",
    "        return enc_map[word] if word in enc_map else enc_map['<RARE>']\n",
    "         \n",
    "    \n",
    "    # identify special characters that separate words : (space) ' ! \" ? @ ^ + * / . , ~ ( ) [ ] { } & | ` $ % = : ; < >  \n",
    "    separator = '(?=[\\s\\'!\"?@\\^+*/\\.,~\\(\\)\\[\\]\\{\\}\\&\\|`\\$\\%\\=:;\\<\\>]|$)'\n",
    "    single_word = '[\\S]+' # non-empty is enough here\n",
    "    \n",
    "    words_list = re.findall(single_word+separator, question)\n",
    "    \n",
    "    return [enc_map['<ST>']] + [map_wrod(word) for word in words_list] + [enc_map['<ED>']] \n",
    "    \n",
    "    \n",
    "def dec_question(question, dec_map):\n",
    "    return [dec_map[enc_value] for enc_value in question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIrH9fwEQOUVI8FKHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc94f266d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8e7f5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_counter = [0]*238 # longest question is 237 words long\n",
    "\n",
    "for i,data in df_train.iterrows():\n",
    "    q1 = eval(data['question1'])\n",
    "    q2 = eval(data['question2'])\n",
    "    \n",
    "    len_counter[len(q1)-2] += 1\n",
    "    len_counter[len(q2)-2] += 1\n",
    "        \n",
    "\n",
    "plt.plot(len_counter)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(len_counter[0:40])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so, use 30 words as length of model input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_to_list_and_clip(data):\n",
    "    clip_len = 30\n",
    "    data['question1'] = eval(data['question1'])[1:-1]\n",
    "    data['question2'] = eval(data['question2'])[1:-1]\n",
    "    \n",
    "    if len(data['question1'])<clip_len:\n",
    "        data['question1'] = data['question1'] + [enc_map['<ED>']] * (30-len(data['question1']))\n",
    "    else:\n",
    "        data['question1'] = data['question1'][:30]\n",
    "        \n",
    "    if len(data['question2'])<clip_len:\n",
    "        data['question2'] = data['question2'] + [enc_map['<ED>']] * (30-len(data['question2']))\n",
    "    else:\n",
    "        data['question2'] = data['question2'][:30]\n",
    "        \n",
    "    return data\n",
    "\n",
    "df_transformed = df_train.apply(change_to_list_and_clip, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(df_transformed, open('./dataset/processed/df_train_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = pickle.load(open('./dataset/processed/df_train_hubertLin_version.pkl', 'rb'))\n",
    "\n",
    "diff_questions = df_transformed.where(df_transformed['is_duplicate']==0).dropna().reset_index(drop=True)\n",
    "same_questions = df_transformed.where(df_transformed['is_duplicate']==1).dropna().reset_index(drop=True)\n",
    "\n",
    "pickle.dump(diff_questions, open('./dataset/processed/df_train_diff_hubertLin_version.pkl', 'wb'))\n",
    "pickle.dump(same_questions, open('./dataset/processed/df_train_same_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = df_test.apply(change_to_list_and_clip, axis=1)\n",
    "pickle.dump(df_transformed, open('./dataset/processed/df_test_hubertLin_version.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_map = pickle.load(open('./dataset/processed/dec_map.pkl','rb'))\n",
    "enc_map = pickle.load(open('./dataset/processed/enc_map.pkl','rb'))\n",
    "embedding_matrix = pickle.load(open('./dataset/processed/embedding_matrix.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_questions = pickle.load(open('./dataset/processed/df_train_diff_hubertLin_version.pkl', 'rb'))\n",
    "same_questions = pickle.load(open('./dataset/processed/df_train_same_hubertLin_version.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, GRU, Reshape, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def naive_model():\n",
    "\n",
    "    # hyper-parameters that should be passed as function argument\n",
    "    \n",
    "    EMBEDDING_SIZE = 300\n",
    "    vocab_size = len(enc_map)\n",
    "    vocab_dim = EMBEDDING_SIZE # in my case is 300\n",
    "    text_length = 30 # how many words are we going to feed in one time\n",
    "    clipnorm = 1\n",
    "\n",
    "    \n",
    "    # embed our encoded question to embedded vector\n",
    "\n",
    "    encoded_question_input1 = Input(shape=(text_length,))\n",
    "\n",
    "    x = Embedding(output_dim = vocab_dim, \n",
    "                  input_dim = vocab_size, \n",
    "                  init = 'glorot_uniform',       # to be honest, I don't know what is this\n",
    "                  input_length = text_length, \n",
    "                  weights = [embedding_matrix]   # our embedding_matrix\n",
    "                 )(encoded_question_input1)\n",
    "\n",
    "    text_embedded1 = Reshape((1,vocab_dim*text_length))(x)\n",
    "    gru1 = GRU(256)(text_embedded1)\n",
    "\n",
    "    \n",
    "    # embed our encoded question to embedded vector\n",
    "\n",
    "    encoded_question_input2 = Input(shape=(text_length,))\n",
    "\n",
    "    x = Embedding(output_dim = vocab_dim, \n",
    "                  input_dim = vocab_size, \n",
    "                  init = 'glorot_uniform',       # to be honest, I don't know what is this\n",
    "                  input_length = text_length, \n",
    "                  weights = [embedding_matrix]   # our embedding_matrix\n",
    "                 )(encoded_question_input2)\n",
    "\n",
    "    text_embedded2 = Reshape((1,vocab_dim*text_length))(x)\n",
    "    gru2 = GRU(256)(text_embedded2)\n",
    "    \n",
    "\n",
    "    # feed to RNN model\n",
    "    x = merge([gru1, gru2], mode='concat', concat_axis=-1)\n",
    "#     x = Reshape((None, 1, 512))(x)\n",
    "    out = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    # compile the model\n",
    "    \n",
    "    model = Model(input=[encoded_question_input1, encoded_question_input2], output=out)\n",
    "    # choose objective and optimizer\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-3), matrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanity_check = same_questions[:10].append(diff_questions[:10])\n",
    "sanity_check = sanity_check.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(embeddings_initializer=\"glorot_uniform\", output_dim=300, weights=[array([[ ..., input_length=30, input_dim=35439)`\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(embeddings_initializer=\"glorot_uniform\", output_dim=300, weights=[array([[ ..., input_length=30, input_dim=35439)`\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model = naive_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 29s - loss: 0.3045 - val_loss: 0.2981\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 29s - loss: 0.3071 - val_loss: 0.3008\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 29s - loss: 0.3035 - val_loss: 0.3092\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 29s - loss: 0.3013 - val_loss: 0.3083\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 29s - loss: 0.3070 - val_loss: 0.2985\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2953 - val_loss: 0.2935\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2979 - val_loss: 0.2888\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2902 - val_loss: 0.2853\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 32s - loss: 0.2971 - val_loss: 0.2963\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2883 - val_loss: 0.3110\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2941 - val_loss: 0.2817\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2907 - val_loss: 0.2868\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2828 - val_loss: 0.2836\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2889 - val_loss: 0.2745\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2803 - val_loss: 0.2805\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2849 - val_loss: 0.2742\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2825 - val_loss: 0.2903\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2773 - val_loss: 0.2687\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2835 - val_loss: 0.2777\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2764 - val_loss: 0.2787\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2674 - val_loss: 0.2747\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2740 - val_loss: 0.2758\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2736 - val_loss: 0.2661\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2667 - val_loss: 0.2818\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2725 - val_loss: 0.2806\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2683 - val_loss: 0.2779\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2621 - val_loss: 0.2750\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2674 - val_loss: 0.2699\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2604 - val_loss: 0.2524\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2607 - val_loss: 0.2736\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2653 - val_loss: 0.2682\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2538 - val_loss: 0.2604\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2560 - val_loss: 0.2715\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2517 - val_loss: 0.2478\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2504 - val_loss: 0.2434\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2487 - val_loss: 0.2695\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2518 - val_loss: 0.2581\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 29s - loss: 0.2467 - val_loss: 0.2350\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2497 - val_loss: 0.2441\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 30s - loss: 0.2423 - val_loss: 0.2360\n",
      "Epoch 41/1000\n",
      " 79/100 [======================>.......] - ETA: 6s - loss: 0.2422"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def gen_suffle_idx(arr):\n",
    "    random.shuffle(arr)\n",
    "    return arr\n",
    "\n",
    "def data_gen():\n",
    "    a = np.arange(batch_size)\n",
    "    while True:\n",
    "        rand = [random.randint(0,len(same_questions)-1) for i in range(batch_size//2)]\n",
    "        pos_selected = same_questions.ix[rand]\n",
    "        rand = [random.randint(0,len(diff_questions)-1) for i in range(batch_size//2)]\n",
    "        neg_selected = diff_questions.ix[rand]\n",
    "        \n",
    "        selected  = pos_selected.append(neg_selected).reset_index(drop=True)\n",
    "        selected = selected.ix[gen_suffle_idx(a)]\n",
    "\n",
    "#         batch_size = len(sanity_check)\n",
    "#         a = np.arange(batch_size)\n",
    "#         selected = sanity_check.ix[gen_suffle_idx(a)]\n",
    "        \n",
    "        q1 = np.array([data['question1'] for i,data in selected.iterrows()])\n",
    "        q2 = np.array([data['question2'] for i,data in selected.iterrows()])\n",
    "        \n",
    "        y = np.zeros( (batch_size,2) )\n",
    "        for i, (k,data) in enumerate(selected.iterrows()):\n",
    "            y[i,int(data['is_duplicate'])] = 1\n",
    "\n",
    "        yield [q1, q2], y\n",
    "\n",
    "def gen_validation(size):\n",
    "    \n",
    "    a = np.arange(size)\n",
    "    \n",
    "    rand = [random.randint(0,len(same_questions)-1) for i in range(size//2)]\n",
    "    pos_selected = same_questions.ix[rand]\n",
    "    rand = [random.randint(0,len(diff_questions)-1) for i in range(size//2)]\n",
    "    neg_selected = diff_questions.ix[rand]\n",
    "    \n",
    "    selected  = pos_selected.append(neg_selected).reset_index(drop=True)\n",
    "    selected = selected.ix[gen_suffle_idx(a)]\n",
    "\n",
    "    q1 = np.array([data['question1'] for i,data in selected.iterrows()])\n",
    "    q2 = np.array([data['question2'] for i,data in selected.iterrows()])\n",
    "    \n",
    "    y = np.zeros( (size,2) )\n",
    "    for i, (k,data) in enumerate(selected.iterrows()):\n",
    "        y[i,int(data['is_duplicate'])] = 1\n",
    "\n",
    "    return [q1, q2], y\n",
    "    \n",
    "try:\n",
    "    validation_data = gen_validation(1024)\n",
    "    model.fit_generator(data_gen(), 100, epochs=1000, validation_data=validation_data)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nEarly stop by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss 約 converge 在 0.5467~0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.433871\n",
      "0.0628152\n",
      "0.674553\n",
      "0.0658139\n",
      "0.00204652\n",
      "0.332731\n",
      "0.0835773\n",
      "0.20868\n",
      "0.124565\n",
      "1.69685e-14\n",
      "0.10288\n",
      "0.523762\n",
      "0.0950808\n",
      "0.0809243\n",
      "0.0602625\n",
      "0.0165486\n",
      "0.000188865\n",
      "0.159509\n",
      "0.0281101\n",
      "0.963905\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    q = diff_questions.ix[i]\n",
    "    x1 = np.array([q['question1']])\n",
    "    x2 = np.array([q['question2']])\n",
    "    print(model.predict([x1,x2])[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def predict(i,q):\n",
    "    \n",
    "#     x1 = np.array([list(q['question1'])])\n",
    "#     x2 = np.array([list(q['question2'])])\n",
    "#     return model.predict([x1,x2])[:,1]\n",
    "\n",
    "# df_test.head()\n",
    "# for i in range(10):\n",
    "#     df = same_questions\n",
    "#     print(dec_question(df.ix[i]['question1'], dec_map))\n",
    "#     print(dec_question(df.ix[i]['question2'], dec_map))\n",
    "#     print(predict(i,df.ix[i]))\n",
    "#     print(df.ix[i]['is_duplicate'])\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./model/HubertLin_naive_2_GRU256_same.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:1210: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "try:\n",
    "    model==None\n",
    "except:\n",
    "    model = load_model('./model/HubertLin_naive_2_GRU256_same.model')\n",
    "\n",
    "df_test = pickle.load(open('./dataset/processed/df_test_hubertLin_version.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2345796\n",
      "10000 / 2345796\n",
      "20000 / 2345796\n",
      "30000 / 2345796\n",
      "40000 / 2345796\n",
      "50000 / 2345796\n",
      "60000 / 2345796\n",
      "70000 / 2345796\n",
      "80000 / 2345796\n",
      "90000 / 2345796\n",
      "100000 / 2345796\n",
      "110000 / 2345796\n",
      "120000 / 2345796\n",
      "130000 / 2345796\n",
      "140000 / 2345796\n",
      "150000 / 2345796\n",
      "160000 / 2345796\n",
      "170000 / 2345796\n",
      "180000 / 2345796\n",
      "190000 / 2345796\n",
      "200000 / 2345796\n",
      "210000 / 2345796\n",
      "220000 / 2345796\n",
      "230000 / 2345796\n",
      "240000 / 2345796\n",
      "250000 / 2345796\n",
      "260000 / 2345796\n",
      "270000 / 2345796\n",
      "280000 / 2345796\n",
      "290000 / 2345796\n",
      "300000 / 2345796\n",
      "310000 / 2345796\n",
      "320000 / 2345796\n",
      "330000 / 2345796\n",
      "340000 / 2345796\n",
      "350000 / 2345796\n",
      "360000 / 2345796\n",
      "370000 / 2345796\n",
      "380000 / 2345796\n",
      "390000 / 2345796\n",
      "400000 / 2345796\n",
      "410000 / 2345796\n",
      "420000 / 2345796\n",
      "430000 / 2345796\n",
      "440000 / 2345796\n",
      "450000 / 2345796\n",
      "460000 / 2345796\n",
      "470000 / 2345796\n",
      "480000 / 2345796\n",
      "490000 / 2345796\n",
      "500000 / 2345796\n",
      "510000 / 2345796\n",
      "520000 / 2345796\n",
      "530000 / 2345796\n",
      "540000 / 2345796\n",
      "550000 / 2345796\n",
      "560000 / 2345796\n",
      "570000 / 2345796\n",
      "580000 / 2345796\n",
      "590000 / 2345796\n",
      "600000 / 2345796\n",
      "610000 / 2345796\n",
      "620000 / 2345796\n",
      "630000 / 2345796\n",
      "640000 / 2345796\n",
      "650000 / 2345796\n",
      "660000 / 2345796\n",
      "670000 / 2345796\n",
      "680000 / 2345796\n",
      "690000 / 2345796\n",
      "700000 / 2345796\n",
      "710000 / 2345796\n",
      "720000 / 2345796\n",
      "730000 / 2345796\n",
      "740000 / 2345796\n",
      "750000 / 2345796\n",
      "760000 / 2345796\n",
      "770000 / 2345796\n",
      "780000 / 2345796\n",
      "790000 / 2345796\n",
      "800000 / 2345796\n",
      "810000 / 2345796\n",
      "820000 / 2345796\n",
      "830000 / 2345796\n",
      "840000 / 2345796\n",
      "850000 / 2345796\n",
      "860000 / 2345796\n",
      "870000 / 2345796\n",
      "880000 / 2345796\n",
      "890000 / 2345796\n",
      "900000 / 2345796\n",
      "910000 / 2345796\n",
      "920000 / 2345796\n",
      "930000 / 2345796\n",
      "940000 / 2345796\n",
      "950000 / 2345796\n",
      "960000 / 2345796\n",
      "970000 / 2345796\n",
      "980000 / 2345796\n",
      "990000 / 2345796\n",
      "1000000 / 2345796\n",
      "1010000 / 2345796\n",
      "1020000 / 2345796\n",
      "1030000 / 2345796\n",
      "1040000 / 2345796\n",
      "1050000 / 2345796\n",
      "1060000 / 2345796\n",
      "1070000 / 2345796\n",
      "1080000 / 2345796\n",
      "1090000 / 2345796\n",
      "1100000 / 2345796\n",
      "1110000 / 2345796\n",
      "1120000 / 2345796\n",
      "1130000 / 2345796\n",
      "1140000 / 2345796\n",
      "1150000 / 2345796\n",
      "1160000 / 2345796\n",
      "1170000 / 2345796\n",
      "1180000 / 2345796\n",
      "1190000 / 2345796\n",
      "1200000 / 2345796\n",
      "1210000 / 2345796\n",
      "1220000 / 2345796\n",
      "1230000 / 2345796\n",
      "1240000 / 2345796\n",
      "1250000 / 2345796\n",
      "1260000 / 2345796\n",
      "1270000 / 2345796\n",
      "1280000 / 2345796\n",
      "1290000 / 2345796\n",
      "1300000 / 2345796\n",
      "1310000 / 2345796\n",
      "1320000 / 2345796\n",
      "1330000 / 2345796\n",
      "1340000 / 2345796\n",
      "1350000 / 2345796\n",
      "1360000 / 2345796\n",
      "1370000 / 2345796\n",
      "1380000 / 2345796\n",
      "1390000 / 2345796\n",
      "1400000 / 2345796\n",
      "1410000 / 2345796\n",
      "1420000 / 2345796\n",
      "1430000 / 2345796\n",
      "1440000 / 2345796\n",
      "1450000 / 2345796\n",
      "1460000 / 2345796\n",
      "1470000 / 2345796\n",
      "1480000 / 2345796\n",
      "1490000 / 2345796\n",
      "1500000 / 2345796\n",
      "1510000 / 2345796\n",
      "1520000 / 2345796\n",
      "1530000 / 2345796\n",
      "1540000 / 2345796\n",
      "1550000 / 2345796\n",
      "1560000 / 2345796\n",
      "1570000 / 2345796\n",
      "1580000 / 2345796\n",
      "1590000 / 2345796\n",
      "1600000 / 2345796\n",
      "1610000 / 2345796\n",
      "1620000 / 2345796\n",
      "1630000 / 2345796\n",
      "1640000 / 2345796\n",
      "1650000 / 2345796\n",
      "1660000 / 2345796\n",
      "1670000 / 2345796\n",
      "1680000 / 2345796\n",
      "1690000 / 2345796\n",
      "1700000 / 2345796\n",
      "1710000 / 2345796\n",
      "1720000 / 2345796\n",
      "1730000 / 2345796\n",
      "1740000 / 2345796\n",
      "1750000 / 2345796\n",
      "1760000 / 2345796\n",
      "1770000 / 2345796\n",
      "1780000 / 2345796\n",
      "1790000 / 2345796\n",
      "1800000 / 2345796\n",
      "1810000 / 2345796\n",
      "1820000 / 2345796\n",
      "1830000 / 2345796\n",
      "1840000 / 2345796\n",
      "1850000 / 2345796\n",
      "1860000 / 2345796\n",
      "1870000 / 2345796\n",
      "1880000 / 2345796\n",
      "1890000 / 2345796\n",
      "1900000 / 2345796\n",
      "1910000 / 2345796\n",
      "1920000 / 2345796\n",
      "1930000 / 2345796\n",
      "1940000 / 2345796\n",
      "1950000 / 2345796\n",
      "1960000 / 2345796\n",
      "1970000 / 2345796\n",
      "1980000 / 2345796\n",
      "1990000 / 2345796\n",
      "2000000 / 2345796\n",
      "2010000 / 2345796\n",
      "2020000 / 2345796\n",
      "2030000 / 2345796\n",
      "2040000 / 2345796\n",
      "2050000 / 2345796\n",
      "2060000 / 2345796\n",
      "2070000 / 2345796\n",
      "2080000 / 2345796\n",
      "2090000 / 2345796\n",
      "2100000 / 2345796\n",
      "2110000 / 2345796\n",
      "2120000 / 2345796\n",
      "2130000 / 2345796\n",
      "2140000 / 2345796\n",
      "2150000 / 2345796\n",
      "2160000 / 2345796\n",
      "2170000 / 2345796\n",
      "2180000 / 2345796\n",
      "2190000 / 2345796\n",
      "2200000 / 2345796\n",
      "2210000 / 2345796\n",
      "2220000 / 2345796\n",
      "2230000 / 2345796\n",
      "2240000 / 2345796\n",
      "2250000 / 2345796\n",
      "2260000 / 2345796\n",
      "2270000 / 2345796\n",
      "2280000 / 2345796\n",
      "2290000 / 2345796\n",
      "2300000 / 2345796\n",
      "2310000 / 2345796\n",
      "2320000 / 2345796\n",
      "2330000 / 2345796\n",
      "2340000 / 2345796\n"
     ]
    }
   ],
   "source": [
    "def predict(i,q):\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(i*1000, '/', len(df_test))\n",
    "    \n",
    "    x1 = np.array(list(q['question1']))\n",
    "    x2 = np.array(list(q['question2']))\n",
    "    return model.predict([x1,x2])[:,1]\n",
    "\n",
    "partition_size = 1000\n",
    "partition_len = len(df_test)//partition_size +1\n",
    "result = [predict(i,df_test.iloc[i*partition_size:(i+1)*partition_size]) for i in range(partition_len)]\n",
    "con = np.concatenate(result)\n",
    "df_result = pd.DataFrame({'test_id':np.arange(len(con)),'is_duplicate':con}, columns=['test_id','is_duplicate'])\n",
    "df_result.to_csv('./result/prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
